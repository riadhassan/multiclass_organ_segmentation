{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8ELDmbn67sZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loader\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.exposure import rescale_intensity\n",
        "\n",
        "\n",
        "class OrganSegmentationDataset(Dataset):\n",
        "\n",
        "  def __init__(\n",
        "        self,\n",
        "        images_dir = '/content/drive/MyDrive/Dataset/segmentation/Covert_mat_into_numpy/processed_data',\n",
        "        # images_dir=\"/content/drive/MyDrive/Research/Image_segmentation/processed_data\",\n",
        "        # images_dir=\"/content/drive/MyDrive/dataset/processed_data\",\n",
        "        subset = \"train\",\n",
        "        traning_patient = 39,\n",
        "        test_length = 1,\n",
        "    ):\n",
        "    self.images_dir = images_dir\n",
        "    self.subset = subset\n",
        "    self.traning_patient = traning_patient\n",
        "    self.data_paths = []\n",
        "    self.patient_ids = []\n",
        "    self.required_test = False\n",
        "    assert subset in [\"all\", \"train\", \"validation\"]\n",
        "\n",
        "    print(\"reading {} images...\".format(subset))\n",
        "    filesPath = glob.glob(images_dir+\"/*.mat\")\n",
        "    if(subset == \"train\"):\n",
        "      for filePath in filesPath:\n",
        "        patient_id = int(filePath.split(\"/\")[-1].split(\"_\")[1])\n",
        "        if patient_id <= traning_patient:\n",
        "          if patient_id not in self.patient_ids:\n",
        "            self.patient_ids.append(patient_id)\n",
        "          self.data_paths.append(filePath)\n",
        "          self.data_paths = sorted(self.data_paths, key=lambda x: int(x.split(\"/\")[-1].split(\"_\")[1].zfill(2) + x.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0].zfill(3)), reverse=False)\n",
        "    \n",
        "    elif (subset == \"validation\"):\n",
        "      filesPath = (filesPath)\n",
        "      for filePath in sorted(filesPath):\n",
        "        patient_id = int(filePath.split(\"/\")[-1].split(\"_\")[1])\n",
        "        if traning_patient+test_length >= patient_id > traning_patient:\n",
        "          if patient_id not in self.patient_ids:\n",
        "            self.patient_ids.append(patient_id)\n",
        "          self.data_paths.append(filePath)\n",
        "          self.data_paths = sorted(self.data_paths)\n",
        "    print(self.patient_ids)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_paths)\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    filePath = self.data_paths[id] \n",
        "    file_name = filePath.split(\"/\")[-1].split(\"_\")\n",
        "    patient_id = int(file_name[1])\n",
        "    slice_id = int(file_name[3].split(\".\")[0])\n",
        "    mat = loadmat(filePath)\n",
        "    mask = mat['seg_img']\n",
        "    image = mat['main_img']\n",
        "\n",
        "    #expand dimention\n",
        "    image = np.expand_dims(image, axis = 2)\n",
        "    \n",
        "    #change shape (C, H, W)\n",
        "    image = image.transpose(2, 0, 1)\n",
        "\n",
        "    image_tensor = torch.from_numpy(image.astype(np.float32))\n",
        "    mask_tensor = torch.from_numpy(mask.astype(int))\n",
        "\n",
        "\n",
        "    return image_tensor, mask_tensor, patient_id, slice_id"
      ],
      "metadata": {
        "id": "XSiS1jtG7ZJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#U-Net Model\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=5, init_features=64):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        output = self.conv(dec1)\n",
        "        return output, dec1\n",
        "    \n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "sD98GQWa7hKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#traning and test data split\n",
        "\n",
        "def data_loaders():\n",
        "    dataset_train, dataset_valid = datasets()\n",
        "\n",
        "    def worker_init(worker_id):\n",
        "        np.random.seed(42 + worker_id)\n",
        "\n",
        "    loader_train = DataLoader(\n",
        "        dataset_train,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=2,\n",
        "        worker_init_fn=worker_init,\n",
        "    )\n",
        "    loader_valid = DataLoader(\n",
        "        dataset_valid,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        num_workers=2,\n",
        "        worker_init_fn=worker_init,\n",
        "    )\n",
        "\n",
        "    return loader_train, loader_valid\n",
        "\n",
        "def datasets():\n",
        "    train = OrganSegmentationDataset(\n",
        "        subset=\"train\"\n",
        "    )\n",
        "    valid = OrganSegmentationDataset(\n",
        "        subset=\"validation\"\n",
        "    )\n",
        "    return train, valid"
      ],
      "metadata": {
        "id": "DdjYKh0z7nux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stored model load\n",
        "\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "def get_prev_traning_data():\n",
        "  last_epoch = 0\n",
        "  checkPoints = sorted(glob.glob(\"/content/drive/MyDrive/Dataset/segmentation/Output/checkpoint_ioU/*.pt\"))\n",
        "  # checkPoints = sorted(glob.glob(\"/content/drive/MyDrive/Research/Image_segmentation/checkpoint/*.pt\"))\n",
        "  for checkPoint in checkPoints:\n",
        "    checkEpoch = int(checkPoint.split('/')[-1].split('_')[1])\n",
        "    if checkEpoch > last_epoch:\n",
        "      last_epoch = checkEpoch\n",
        "      last_checkpoint = checkPoint\n",
        "\n",
        "  if len(checkPoints) != 0:\n",
        "    return torch.load(last_checkpoint)\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "fx5UFDX-7zkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_toolbelt\n",
        "!pip install pytorch-ignite"
      ],
      "metadata": {
        "id": "GFoKYujr75RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pixel deviation based loss\n",
        "\n",
        "import torch\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "def pixDeviationLoss(img, pred, true):\n",
        "  pred = torch.argmax(pred, 0).squeeze()\n",
        "  true = true.squeeze()\n",
        "  miss_match = ~torch.eq(true, pred).int()\n",
        "  \n",
        "  img = img.squeeze()\n",
        "\n",
        "  return torch.sum(torch.abs(torch.mul(img, miss_match)), (0, 1))"
      ],
      "metadata": {
        "id": "F1FK_T6b78zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and save model\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "import torch.utils.tensorboard as tb\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.functional import one_hot\n",
        "from pytorch_toolbelt import losses\n",
        "from ignite.engine import *\n",
        "from ignite.handlers import *\n",
        "from ignite.metrics import *\n",
        "import csv\n",
        "\n",
        "\n",
        "def eval_step(engine, batch):\n",
        "    return batch\n",
        "\n",
        "default_evaluator = Engine(eval_step)\n",
        "\n",
        "cm = ConfusionMatrix(num_classes=5)\n",
        "metric = DiceCoefficient(cm)\n",
        "metric.attach(default_evaluator, 'dice')\n",
        "\n",
        "# max_slice_count = get_max_slice_count()\n",
        "\n",
        "log_dir = tempfile.mkdtemp()\n",
        "%tensorboard --logdir {log_dir} --reload_interval 1\n",
        "writer = tb.SummaryWriter(log_dir, flush_secs=1)\n",
        "\n",
        "device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda:0\")\n",
        "\n",
        "loader_train, loader_valid = data_loaders()\n",
        "loaders = {\"train\": loader_train, \"valid\": loader_valid}\n",
        "\n",
        "unet = UNet(in_channels=1, out_channels=5)\n",
        "unet.to(device)\n",
        "dice_val = DiceVal()\n",
        "loss_function = losses.JaccardLoss(mode = \"multiclass\")\n",
        "best_validation_dsc = 0.0\n",
        "optimizer = optim.Adam(unet.parameters(), lr=0.0001)\n",
        "# loss_function = nn.CrossEntropyLoss()\n",
        "loss_function_validatiion = losses.DiceLoss(mode = \"multiclass\")\n",
        "\n",
        "loss_train_final = []\n",
        "dice_valid_final = []\n",
        "Valid_loss_final = []\n",
        "\n",
        "\n",
        "epoch_num = 50\n",
        "\n",
        "done_epoch = 0\n",
        "prev_traning_data = get_prev_traning_data()\n",
        "\n",
        "if prev_traning_data:\n",
        "  print(\"hello\")\n",
        "  done_epoch = prev_traning_data['epoch']\n",
        "  loss = prev_traning_data['loss']\n",
        "  unet.load_state_dict(prev_traning_data['model_state_dict'])\n",
        "  optimizer.load_state_dict(prev_traning_data['optimizer_state_dict'])\n",
        "                       \n",
        "\n",
        "for epoch in tqdm(range(done_epoch+1, epoch_num+1)):\n",
        "  print(\"{epc} is running\".format(epc = epoch))\n",
        "  loss_train = []\n",
        "  loss_valid = []\n",
        "  Dice_valid = []\n",
        "  Dice_per_organ = {}\n",
        "  step = 0\n",
        "  img_print = 0\n",
        "\n",
        "  for phase in [\"train\", 'valid']:\n",
        "    if phase == \"train\":\n",
        "      validation_predict = {}\n",
        "      validation_true = {}\n",
        "      unet.train()\n",
        "    else:\n",
        "      unet.eval()\n",
        "\n",
        "    for i, data in enumerate(loaders[phase]):\n",
        "      x, y_true, patient_id , slice_id = data\n",
        "      x, y_true = x.to(device), y_true.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.set_grad_enabled(phase == \"train\"):\n",
        "        y_pred = unet(x)\n",
        "        # loss = loss_function(y_pred, y_true)\n",
        "        loss = loss_function(y_pred, y_true) + pixDeviationLoss(x, y_pred, y_true)  \n",
        "\n",
        "\n",
        "        if phase == \"valid\":\n",
        "          loss = loss_function_validatiion(y_pred, y_true)\n",
        "          loss_valid.append(float(loss.item()))\n",
        "          step = step + 1\n",
        "\n",
        "          patient_id = int(patient_id)\n",
        "          slice_id = int(slice_id)\n",
        "\n",
        "          if patient_id not in validation_predict.keys():\n",
        "            validation_predict[patient_id] = y_pred\n",
        "            validation_true[patient_id] = y_true\n",
        "          else:\n",
        "            validation_predict[patient_id] = torch.cat((validation_predict[patient_id], y_pred))\n",
        "            validation_true[patient_id] = torch.cat((validation_true[patient_id], y_true))\n",
        "\n",
        "          if (img_print % 70) == 0:\n",
        "            y_pred_np = y_pred.detach().cpu().numpy().squeeze()\n",
        "            y_pred_np = np.argmax(y_pred_np, 0)\n",
        "            y_true_np = y_true.detach().cpu().numpy().squeeze()\n",
        "            main_image_np = x.detach().cpu().numpy().squeeze()\n",
        "            plt.figure(img_print)\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(main_image_np)\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(y_true_np)\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(y_pred_np)\n",
        "            plt.show()\n",
        "          img_print = img_print + 1\n",
        "\n",
        "        if phase == \"train\":\n",
        "          loss_train.append(float(loss.item()))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "  all_dice_per_organ = torch.zeros(1,5)\n",
        "  for patient in validation_predict.keys():\n",
        "    val_patient_pred = validation_predict[patient]\n",
        "    val_patient_true = validation_true[patient]\n",
        "    dice = 1 - loss_function_validatiion(val_patient_pred, val_patient_true)\n",
        "    Dice_valid.append(float(dice.item()))\n",
        "\n",
        "    dice_per_organ = default_evaluator.run([[val_patient_pred, val_patient_true]])\n",
        "    dice_per_organ = dice_per_organ.metrics['dice']\n",
        "    dice_per_organ = dice_per_organ[None, :]\n",
        "    all_dice_per_organ = torch.cat((all_dice_per_organ, dice_per_organ), 0)\n",
        "\n",
        "  avg_all_dice_per_organ = torch.mean(all_dice_per_organ[1:],0)\n",
        "\n",
        "  t_loss = np.mean(np.array(loss_train))\n",
        "  v_loss = np.mean(np.array(loss_valid))\n",
        "  V_dice = np.mean(np.array(Dice_valid))\n",
        "\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/Dataset/segmentation/Output/D_loss_data_IoU.csv\", 'a') as f:\n",
        "  # with open(\"/content/drive/MyDrive/dataset/Output/data_IoU.csv\", 'a') as f:\n",
        "    csv_writer = csv.writer(f, delimiter=',')\n",
        "    csv_writer.writerow([epoch, t_loss, v_loss, V_dice, avg_all_dice_per_organ[0].item(), avg_all_dice_per_organ[1].item(), avg_all_dice_per_organ[2].item(), avg_all_dice_per_organ[3].item(), avg_all_dice_per_organ[4].item()])\n",
        "\n",
        "  loss_train_final.append(t_loss)\n",
        "  writer.add_scalar(\"train Loss\", t_loss, epoch)\n",
        "  dice_valid_final.append(V_dice)\n",
        "  writer.add_scalar(\"validation IoU\", V_dice, epoch)\n",
        "  Valid_loss_final.append(v_loss)\n",
        "  writer.add_scalar(\"validation loss\", v_loss, epoch)\n",
        "  \n",
        "  for i in range(5):\n",
        "    writer.add_scalar(\"Organ IoU/{organ}\".format(organ=i), float(avg_all_dice_per_organ[i].item()), epoch)\n",
        "    \n",
        "  check_file = \"/content/drive/MyDrive/Dataset/segmentation/Output/D_loss_checkpoint_ioU/IoU_seg_{ep}_{dic}.pt\".format(ep=epoch, dic = V_dice)\n",
        "  # check_file = \"/content/drive/MyDrive/dataset/Output/checkpoint_IoU/seg_{ep}_{dic}.pt\".format(ep=epoch, dic = V_dice)\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': unet.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            't_loss': t_loss,\n",
        "            'v_loss': v_loss,\n",
        "            'V_dice': V_dice,\n",
        "            'dice_01': avg_all_dice_per_organ\n",
        "            }, check_file)\n",
        "\n",
        "writer.flush()\n",
        "\n",
        "trl = [i for i in range(1,len(loss_train_final)+1)]\n",
        "plt.figure(\"test loss\")\n",
        "plt.plot(trl, loss_train_final)\n",
        "plt.show()\n",
        "\n",
        "vpl = [i for i in range(1,len(dice_valid_final)+1)]\n",
        "plt.figure(\"Valid IoU\")\n",
        "plt.plot(vpl, dice_valid_final)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k8Ch9pLn8HBh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}